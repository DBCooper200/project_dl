{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRsl76GTDEZhreFY0pko7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DBCooper200/project_dl/blob/main/trying_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g3pDl_f4Ytph"
      },
      "outputs": [],
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COoUoONcZadr",
        "outputId": "aaa55895-ee81-4cd9-b7d2-6589d35d9a5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 67 May 23 16:59 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "fTQSZgYeZa-6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d himanshuagarwal1998/glaucomadataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2UNjur2Zgjp",
        "outputId": "d05c4d07-798f-4a80-c75b-351400ff1e3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading glaucomadataset.zip to /content\n",
            " 99% 2.52G/2.54G [00:23<00:00, 208MB/s]\n",
            "100% 2.54G/2.54G [00:23<00:00, 115MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/Data_set\n",
        "!unzip -q /content/glaucomadataset.zip -d /content/Data_set"
      ],
      "metadata": {
        "id": "E4KOldYyZmJF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "PrJFITQIZoa5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = ['/content/Data_set/Non Glaucoma', '/content/Data_set/Glaucoma']\n",
        "images = []\n",
        "labels = []\n",
        "for n,i in enumerate(path):\n",
        "    for j in tqdm(os.listdir(i)):\n",
        "        img_path = os.path.join(i,j)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (64,64))\n",
        "        images.append(img)\n",
        "        labels.append(n)\n",
        "images = np.array(images)/255\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfc0ng2EZqhm",
        "outputId": "03b6004d-369d-476b-8da3-92d32e958962"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 511/511 [00:40<00:00, 12.52it/s]\n",
            "100%|██████████| 511/511 [00:09<00:00, 52.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in enumerate(path):\n",
        "  print(n)\n",
        "\n",
        "#the labels assigned are \n",
        "# 0 for non glaucomic images\n",
        "# 1 for glaucomic images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKWwoI9HZsf6",
        "outputId": "ecae365b-30c3-4052-b1fe-ce6768cc9931"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '/content/Data_set/Non Glaucoma')\n",
            "(1, '/content/Data_set/Glaucoma')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "images, labels = shuffle(images, labels, random_state=32)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(images, labels, test_size=0.15, random_state=44)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.15, random_state=40)\n",
        "     "
      ],
      "metadata": {
        "id": "gJ5SFhNTZuv0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(zoom_range=0.2, horizontal_flip=True, vertical_flip=True,\n",
        "                            fill_mode='constant', cval=0.)\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=32)\n",
        "#Using TensorFlow backend.\n",
        "\n",
        "#for test set\n",
        "test_gen = datagen.flow(x_test, y_test, batch_size = 32)"
      ],
      "metadata": {
        "id": "Va8yUgRzZyO4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initializer = tf.keras.initializers.HeNormal()"
      ],
      "metadata": {
        "id": "xgIsy3eumU7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, input_shape=(64,64), activation='relu',kernel_initializer=initializer))\n",
        "model.add(Dense(128, activation='relu',kernel_initializer=initializer))\n",
        "#model.add(Dense(333, activation='relu',kernel_initializer=initializer))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "tb_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
        "#the above is done to get tensorboard logs which are then referred by callback parameter below\n",
        "model.fit_generator(train_gen, epochs=10, steps_per_epoch=1,verbose=1, validation_data=(x_valid,y_valid),callbacks=[tb_callback])\n",
        "'''\n",
        "model.fit(x_train, y_train,steps_per_epoch=1, epochs=100,verbose=\"auto\",callbacks=[tb_callback],validation_data=(x_valid,y_valid))                              \n",
        "model.summary()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "l6IjqeQJZ2lb",
        "outputId": "eaa2c292-b698-488b-9c8c-6bebd8a1f76c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.8818 - accuracy: 0.6250 - val_loss: 4.8816 - val_accuracy: 0.5390\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 4.5018 - accuracy: 0.5938 - val_loss: 1.1064 - val_accuracy: 0.5390\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 0.9284 - accuracy: 0.5938 - val_loss: 1.2561 - val_accuracy: 0.5390\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 540ms/step - loss: 1.5398 - accuracy: 0.5625 - val_loss: 0.8637 - val_accuracy: 0.5390\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 1.7070 - accuracy: 0.6562 - val_loss: 0.4370 - val_accuracy: 0.5390\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 0.4897 - accuracy: 0.3438 - val_loss: 0.6663 - val_accuracy: 0.5390\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 574ms/step - loss: 0.7995 - accuracy: 0.4375 - val_loss: 0.5131 - val_accuracy: 0.5390\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 0.5302 - accuracy: 0.5000 - val_loss: 0.3533 - val_accuracy: 0.5390\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 575ms/step - loss: 0.4185 - accuracy: 0.5938 - val_loss: 0.3334 - val_accuracy: 0.5390\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.4798 - accuracy: 0.4375 - val_loss: 0.3477 - val_accuracy: 0.5390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel.fit(x_train, y_train,steps_per_epoch=1, epochs=100,verbose=\"auto\",callbacks=[tb_callback],validation_data=(x_valid,y_valid))                              \\nmodel.summary()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6nGY7mZnaitt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrSN6azncaJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
        "#the above is done to get tensorboard logs which are then referred by callback parameter below\n",
        "history = classifier.fit_generator(train_gen, epochs=100, steps_per_epoch=1,\n",
        "                              verbose=1, validation_data=(x_valid,y_valid),\n",
        "                              callbacks=[tb_callback])\n",
        "#Number of Steps per Epoch = (Total Number of Training Samples) / (Batch Size)\n",
        "#callbacks reqd as logs were needed and manual saving of model will be done furthur to the disk"
      ],
      "metadata": {
        "id": "kxjGTijnar7X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}